---
phase: 01-domain-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - apps/api/src/infrastructure/database/drizzle/schema/ingestion-batches.schema.ts
  - apps/api/src/infrastructure/database/drizzle/schema/ingestion-rows.schema.ts
  - apps/api/src/infrastructure/database/drizzle/schema/index.ts
  - apps/api/src/infrastructure/database/drizzle/mappers/batch.mapper.ts
  - apps/api/src/infrastructure/database/drizzle/mappers/row.mapper.ts
  - apps/api/src/infrastructure/database/drizzle/repositories/drizzle-batch.repository.ts
  - apps/api/src/infrastructure/database/drizzle/repositories/drizzle-row.repository.ts
  - apps/api/src/infrastructure/database/drizzle/drizzle.module.ts
autonomous: true

must_haves:
  truths:
    - "ingestion_batches and ingestion_rows Drizzle schemas define the database structure with proper FK relationships (rows -> batches -> projects)"
    - "DrizzleBatchRepository implements all BatchRepository abstract methods using Drizzle ORM"
    - "DrizzleRowRepository implements RowRepository with createMany chunking at ~5,000 rows per INSERT to stay under PostgreSQL 65,534 parameter limit"
    - "Both repositories are registered in DrizzleModule using the provide/useClass pattern"
    - "A Drizzle migration file is generated for the new tables"
    - "Mappers normalize undefined to null before JSONB storage (Pitfall 11)"
  artifacts:
    - path: "apps/api/src/infrastructure/database/drizzle/schema/ingestion-batches.schema.ts"
      provides: "ingestion_batches table definition with FK to projects, pgEnums for batch_status and batch_mode"
      contains: "pgTable.*ingestion_batches"
    - path: "apps/api/src/infrastructure/database/drizzle/schema/ingestion-rows.schema.ts"
      provides: "ingestion_rows table definition with FK to ingestion_batches, pgEnum for row_status"
      contains: "pgTable.*ingestion_rows"
    - path: "apps/api/src/infrastructure/database/drizzle/repositories/drizzle-batch.repository.ts"
      provides: "DrizzleBatchRepository extending BatchRepository"
      contains: "extends BatchRepository"
    - path: "apps/api/src/infrastructure/database/drizzle/repositories/drizzle-row.repository.ts"
      provides: "DrizzleRowRepository with chunked createMany"
      contains: "extends RowRepository"
    - path: "apps/api/src/infrastructure/database/drizzle/mappers/batch.mapper.ts"
      provides: "BatchMapper with toDomain static method"
      contains: "class BatchMapper"
    - path: "apps/api/src/infrastructure/database/drizzle/mappers/row.mapper.ts"
      provides: "RowMapper with toDomain static method, undefined-to-null normalization"
      contains: "class RowMapper"
    - path: "apps/api/src/infrastructure/database/drizzle/drizzle.module.ts"
      provides: "Updated module with Batch/Row repository providers"
      contains: "BatchRepository.*DrizzleBatchRepository"
  key_links:
    - from: "apps/api/src/infrastructure/database/drizzle/schema/ingestion-batches.schema.ts"
      to: "apps/api/src/infrastructure/database/drizzle/schema/projects.schema.ts"
      via: "foreign key reference"
      pattern: "references.*projects\\.id"
    - from: "apps/api/src/infrastructure/database/drizzle/schema/ingestion-rows.schema.ts"
      to: "apps/api/src/infrastructure/database/drizzle/schema/ingestion-batches.schema.ts"
      via: "foreign key reference"
      pattern: "references.*ingestionBatches\\.id"
    - from: "apps/api/src/infrastructure/database/drizzle/drizzle.module.ts"
      to: "apps/api/src/core/repositories/batch.repository.ts"
      via: "provide abstract class, useClass implementation"
      pattern: "provide: BatchRepository"
    - from: "apps/api/src/infrastructure/database/drizzle/drizzle.module.ts"
      to: "apps/api/src/core/repositories/row.repository.ts"
      via: "provide abstract class, useClass implementation"
      pattern: "provide: RowRepository"
---

<objective>
Create the Infrastructure layer for the ingestion pipeline: Drizzle schemas for `ingestion_batches` and `ingestion_rows` tables, mappers, repository implementations, DrizzleModule registration, and database migration generation.

Purpose: Wire the persistent storage layer that fulfills the Core layer contracts created in Plan 01, following the exact implementation patterns established in v1.0 (DrizzleUserRepository, DrizzleProjectRepository, UserMapper, ProjectMapper).

Output: 7 new/modified files + 1 generated migration.
</objective>

<execution_context>
@/Users/luanmartins/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luanmartins/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-domain-foundation/01-CONTEXT.md
@.planning/phases/01-domain-foundation/01-01-SUMMARY.md

# Existing patterns to follow exactly:
@apps/api/src/infrastructure/database/drizzle/schema/users.schema.ts
@apps/api/src/infrastructure/database/drizzle/schema/projects.schema.ts
@apps/api/src/infrastructure/database/drizzle/schema/index.ts
@apps/api/src/infrastructure/database/drizzle/mappers/user.mapper.ts
@apps/api/src/infrastructure/database/drizzle/mappers/project.mapper.ts
@apps/api/src/infrastructure/database/drizzle/repositories/drizzle-user.repository.ts
@apps/api/src/infrastructure/database/drizzle/repositories/drizzle-project.repository.ts
@apps/api/src/infrastructure/database/drizzle/drizzle.module.ts
@apps/api/drizzle.config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Drizzle schemas for ingestion_batches and ingestion_rows tables</name>
  <files>
    apps/api/src/infrastructure/database/drizzle/schema/ingestion-batches.schema.ts
    apps/api/src/infrastructure/database/drizzle/schema/ingestion-rows.schema.ts
    apps/api/src/infrastructure/database/drizzle/schema/index.ts
  </files>
  <action>
Create `ingestion-batches.schema.ts` following the exact pattern from `projects.schema.ts`:

```typescript
import {
  pgTable,
  pgEnum,
  uuid,
  text,
  integer,
  jsonb,
  timestamp,
  index,
} from 'drizzle-orm/pg-core';

import { projects } from './projects.schema';
import { users } from './users.schema';
```

**Define pgEnums** (lowercase values in DB, matching `projectStatusEnum` pattern):
- `batchStatusEnum = pgEnum('batch_status', ['pending_review', 'completed', 'failed'])`
- `batchModeEnum = pgEnum('batch_mode', ['list_mode', 'profile_mode'])`

**Define `ingestionBatches` table** (variable name camelCase, table name snake_case with domain prefix per CONTEXT.md):

Table name: `'ingestion_batches'`

Columns:
- `id: uuid('id').primaryKey().defaultRandom()`
- `projectId: uuid('project_id').notNull().references(() => projects.id)` -- FK to projects, no cascade (ON DELETE RESTRICT is default, per CONTEXT.md)
- `userId: uuid('user_id').notNull().references(() => users.id)` -- FK to users
- `mode: batchModeEnum('mode').notNull()`
- `status: batchStatusEnum('status').notNull().default('pending_review')`
- `fileCount: integer('file_count').notNull()`
- `rowCount: integer('row_count').notNull()`
- `columnMetadata: jsonb('column_metadata').notNull().default('[]')` -- Pitfall 19: array of ColumnMetadata objects
- `createdAt: timestamp('created_at', { withTimezone: true }).defaultNow()`
- `updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow()`
- `deletedAt: timestamp('deleted_at', { withTimezone: true })`
- `deletedBy: uuid('deleted_by').references(() => users.id)` -- nullable, audit trail per CONTEXT.md

Indexes (following projects.schema.ts pattern with callback returning array):
- `index('idx_ingestion_batches_project_id').on(table.projectId)` -- lookup by project
- `index('idx_ingestion_batches_user_id').on(table.userId)` -- lookup by user

Export inferred types:
```typescript
export type IngestionBatchRow = typeof ingestionBatches.$inferSelect;
export type IngestionBatchInsert = typeof ingestionBatches.$inferInsert;
```

Create `ingestion-rows.schema.ts`:

**Define pgEnum:**
- `rowStatusEnum = pgEnum('row_status', ['valid', 'warning', 'error'])`

**Define `ingestionRows` table:**

Table name: `'ingestion_rows'`

Columns:
- `id: uuid('id').primaryKey().defaultRandom()`
- `batchId: uuid('batch_id').notNull().references(() => ingestionBatches.id)` -- FK to ingestion_batches
- `data: jsonb('data').notNull()` -- REQ-06: JSONB normalized data
- `status: rowStatusEnum('status').notNull().default('valid')`
- `validationMessages: jsonb('validation_messages').notNull().default('[]')` -- structured array
- `sourceFileName: text('source_file_name').notNull()` -- REQ-07: source traceability
- `sourceSheetName: text('source_sheet_name').notNull()`
- `sourceRowIndex: integer('source_row_index').notNull()`
- `createdAt: timestamp('created_at', { withTimezone: true }).defaultNow()`
- `updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow()`
- `deletedAt: timestamp('deleted_at', { withTimezone: true })`

Indexes:
- `index('idx_ingestion_rows_batch_id').on(table.batchId)` -- lookup by batch (critical for queries)

Export inferred types:
```typescript
export type IngestionRowRow = typeof ingestionRows.$inferSelect;
export type IngestionRowInsert = typeof ingestionRows.$inferInsert;
```

**Update `schema/index.ts` barrel** to add:
```typescript
export * from './ingestion-batches.schema';
export * from './ingestion-rows.schema';
```

**Important:** After adding the schemas to the barrel, the `DrizzleService` will automatically pick them up since it does `import * as schema from './schema'` and passes it to `drizzle(this.pool, { schema })`. This means Drizzle's relational query builder will know about the new tables.

**Generate migration** by running from `apps/api`:
```bash
npx drizzle-kit generate
```

This reads `drizzle.config.ts` which points to `./src/infrastructure/database/drizzle/schema/index.ts` and outputs to `./drizzle/`. A new SQL migration file will be created. Do NOT run `drizzle-kit push` or `drizzle-kit migrate` -- just generate.

**Note on FK behavior:** The default Drizzle FK behavior is `ON DELETE no action ON UPDATE no action` (visible in existing migration `0000_mysterious_mordo.sql`). This effectively acts as RESTRICT at the database level, which matches CONTEXT.md decision for `ON DELETE RESTRICT`.
  </action>
  <verify>
Run `npx tsc --noEmit --project apps/api/tsconfig.json` from repo root -- should pass with no errors.
Verify migration was generated: `ls apps/api/drizzle/*.sql | wc -l` should show 2 (original + new).
Verify schema barrel exports: `grep -c "export \*" apps/api/src/infrastructure/database/drizzle/schema/index.ts` should show 4 lines.
  </verify>
  <done>
`ingestion_batches` table schema exists with FK to projects and users, batch_status enum (pending_review, completed, failed), batch_mode enum (list_mode, profile_mode), columnMetadata JSONB, and deletedBy audit field. `ingestion_rows` table schema exists with FK to ingestion_batches, data JSONB, row_status enum, validationMessages JSONB, source traceability fields (fileName, sheetName, rowIndex). Both schemas export inferred Row/Insert types. Schema barrel updated. Migration generated.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create mappers and repository implementations, register in DrizzleModule</name>
  <files>
    apps/api/src/infrastructure/database/drizzle/mappers/batch.mapper.ts
    apps/api/src/infrastructure/database/drizzle/mappers/row.mapper.ts
    apps/api/src/infrastructure/database/drizzle/repositories/drizzle-batch.repository.ts
    apps/api/src/infrastructure/database/drizzle/repositories/drizzle-row.repository.ts
    apps/api/src/infrastructure/database/drizzle/drizzle.module.ts
  </files>
  <action>
**Create `batch.mapper.ts`** following the exact pattern from `project.mapper.ts`:

```typescript
import {
  Batch,
  BatchMode,
  BatchStatus,
  ColumnMetadata,
} from '../../../../core/entities/batch.entity';
import type { IngestionBatchRow } from '../schema/ingestion-batches.schema';

export class BatchMapper {
  public static toDomain(row: IngestionBatchRow): Batch {
    return {
      id: row.id,
      projectId: row.projectId,
      userId: row.userId,
      mode: row.mode as BatchMode,
      status: row.status as BatchStatus,
      fileCount: row.fileCount,
      rowCount: row.rowCount,
      columnMetadata: (row.columnMetadata ?? []) as ColumnMetadata[],
      createdAt: row.createdAt ?? new Date(),
      updatedAt: row.updatedAt ?? new Date(),
      deletedAt: row.deletedAt ?? null,    // Pitfall 11: normalize undefined to null
      deletedBy: row.deletedBy ?? null,     // Pitfall 11: normalize undefined to null
    };
  }
}
```

**Key pattern:** Use `as BatchStatus` / `as BatchMode` for enum casting, exactly like ProjectMapper uses `row.status as ProjectStatus`. Use `?? new Date()` for timestamps, matching existing mappers. Use `?? null` for nullable fields to normalize any `undefined` to `null` (Pitfall 11).

**Create `row.mapper.ts`:**

```typescript
import {
  Row,
  RowStatus,
  ValidationMessage,
} from '../../../../core/entities/row.entity';
import type { IngestionRowRow } from '../schema/ingestion-rows.schema';

export class RowMapper {
  public static toDomain(row: IngestionRowRow): Row {
    return {
      id: row.id,
      batchId: row.batchId,
      data: (row.data ?? {}) as Record<string, unknown>,
      status: row.status as RowStatus,
      validationMessages: (row.validationMessages ?? []) as ValidationMessage[],
      sourceFileName: row.sourceFileName,
      sourceSheetName: row.sourceSheetName,
      sourceRowIndex: row.sourceRowIndex,
      createdAt: row.createdAt ?? new Date(),
      updatedAt: row.updatedAt ?? new Date(),
      deletedAt: row.deletedAt ?? null,     // Pitfall 11: normalize undefined to null
    };
  }
}
```

**Create `drizzle-batch.repository.ts`** following `drizzle-project.repository.ts` pattern:

- `@Injectable()` class extending `BatchRepository`
- Constructor: `private readonly drizzle: DrizzleService` via DI, call `super()`
- Import `and, eq, isNull` from `drizzle-orm` (same as project repo)
- Import `ingestionBatches` from `'../schema'`
- Import `BatchMapper` from `'../mappers/batch.mapper'`

Methods:

`create(data: CreateBatchData): Promise<Batch>` -- Insert with `.returning()`, map result. Use `data.columnMetadata` directly as JSONB value (Drizzle handles serialization). Follow exact pattern from `DrizzleProjectRepository.create()`.

`findById(id: string): Promise<Batch | null>` -- Select with `eq(ingestionBatches.id, id)` AND `isNull(ingestionBatches.deletedAt)`, `.limit(1)`. Map first result or return null. Follows project repo pattern.

`findByProjectId(projectId: string): Promise<Batch[]>` -- Select with `eq(ingestionBatches.projectId, projectId)` AND `isNull(ingestionBatches.deletedAt)`, ordered by `ingestionBatches.createdAt`. Map all results. Follows `findAllByUserId` pattern.

`softDelete(id: string, deletedBy: string): Promise<void>` -- Update setting `deletedAt: new Date()`, `deletedBy`, `updatedAt: new Date()` where `eq(id)` AND `isNull(deletedAt)`. Follows project repo `softDelete` pattern but adds `deletedBy` field.

**Create `drizzle-row.repository.ts`:**

- `@Injectable()` class extending `RowRepository`
- Constructor: `private readonly drizzle: DrizzleService`
- Import `ingestionRows` from `'../schema'`

Methods:

`createMany(data: CreateRowData[]): Promise<void>` -- **Critical: Pitfall 5 chunking implementation.**

PostgreSQL has a 65,534 parameter limit per query. Each row insert has ~9 parameters (batchId, data, status, validationMessages, sourceFileName, sourceSheetName, sourceRowIndex + defaults). To stay safe: chunk at 5,000 rows per INSERT.

Implementation:
```typescript
public async createMany(data: CreateRowData[]): Promise<void> {
  const CHUNK_SIZE = 5000;

  for (let i = 0; i < data.length; i += CHUNK_SIZE) {
    const chunk = data.slice(i, i + CHUNK_SIZE);
    const values = chunk.map((row) => ({
      batchId: row.batchId,
      data: row.data,
      status: row.status ?? 'valid',
      validationMessages: row.validationMessages ?? [],
      sourceFileName: row.sourceFileName,
      sourceSheetName: row.sourceSheetName,
      sourceRowIndex: row.sourceRowIndex,
    }));

    // Pitfall 16: Omit .returning() on bulk inserts
    await this.drizzle
      .getClient()
      .insert(ingestionRows)
      .values(values);
  }
}
```

**Note:** Use the lowercase enum string values directly (e.g., `'valid'`) because the pgEnum in the schema uses lowercase values. The status default in CreateRowData maps to the DB enum value. Pitfall 11: normalize `status` to `'valid'` and `validationMessages` to `[]` when undefined.

`findByBatchId(batchId: string): Promise<Row[]>` -- Select with `eq(ingestionRows.batchId, batchId)` AND `isNull(ingestionRows.deletedAt)`. Map all results with `RowMapper.toDomain`. Follows `findAllByUserId` pattern.

**Update `drizzle.module.ts`** to register new repositories following the exact provider pattern:

Add imports for `BatchRepository` and `RowRepository` from core, `DrizzleBatchRepository` and `DrizzleRowRepository` from infrastructure.

Add to providers array:
```typescript
{
  provide: BatchRepository,
  useClass: DrizzleBatchRepository,
},
{
  provide: RowRepository,
  useClass: DrizzleRowRepository,
},
```

Add `BatchRepository` and `RowRepository` to exports array.

The module is `@Global()` so these will be injectable throughout the app without additional imports.
  </action>
  <verify>
Run `npx tsc --noEmit --project apps/api/tsconfig.json` from repo root -- should pass with no errors.
Verify DrizzleModule has 4 repository providers: `grep -c "provide:" apps/api/src/infrastructure/database/drizzle/drizzle.module.ts` should show 4.
Verify chunking constant exists: `grep "CHUNK_SIZE" apps/api/src/infrastructure/database/drizzle/repositories/drizzle-row.repository.ts` should show match.
Verify Pitfall 16 (no .returning on bulk): `grep -c "returning" apps/api/src/infrastructure/database/drizzle/repositories/drizzle-row.repository.ts` should show 0.
  </verify>
  <done>
BatchMapper.toDomain converts DB rows to Batch entities with enum casting and undefined-to-null normalization. RowMapper.toDomain converts DB rows to Row entities with JSONB casting and undefined-to-null normalization. DrizzleBatchRepository implements create, findById, findByProjectId, softDelete (with deletedBy audit). DrizzleRowRepository implements createMany with 5,000-row chunking (Pitfall 5) and no .returning() (Pitfall 16), plus findByBatchId. DrizzleModule registers both new repositories with provide/useClass pattern and exports them globally.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit --project apps/api/tsconfig.json` passes with no errors
2. Migration file exists in `apps/api/drizzle/` directory (2 SQL files total)
3. DrizzleModule providers array has 4 entries (UserRepository, ProjectRepository, BatchRepository, RowRepository)
4. DrizzleModule exports array has 5 entries (DrizzleService + 4 repositories)
5. `createMany` implementation chunks at 5,000 rows and does NOT call `.returning()`
6. Both mappers normalize `undefined` to `null` using `??` operator
7. All soft-delete queries filter `isNull(deletedAt)`
8. Schema FK references point to correct parent tables (ingestion_batches -> projects, ingestion_rows -> ingestion_batches)
</verification>

<success_criteria>
- `ingestion_batches` Drizzle schema has: id, projectId (FK projects), userId (FK users), mode (pgEnum), status (pgEnum), fileCount, rowCount, columnMetadata (jsonb), timestamps, deletedAt, deletedBy (FK users)
- `ingestion_rows` Drizzle schema has: id, batchId (FK ingestion_batches), data (jsonb), status (pgEnum), validationMessages (jsonb), sourceFileName, sourceSheetName, sourceRowIndex, timestamps, deletedAt
- Migration file generated successfully
- DrizzleBatchRepository extends BatchRepository with create, findById, findByProjectId, softDelete
- DrizzleRowRepository extends RowRepository with createMany (5,000 chunk, no returning) and findByBatchId
- BatchMapper and RowMapper convert DB rows to domain entities with undefined-to-null normalization
- DrizzleModule registers and exports BatchRepository and RowRepository
- TypeScript compilation succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/01-domain-foundation/01-02-SUMMARY.md`
</output>
